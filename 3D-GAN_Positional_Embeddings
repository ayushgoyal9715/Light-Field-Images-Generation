import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from pytorch_msssim import SSIM
import os
from tqdm import tqdm # For a nice progress bar

# --- Assume your data_generation.py file is named `data_generation.py` ---
# This will import the excellent, robust LightFieldDataset class we just created.
from new_data import LightFieldDataset


# --- MODELS (UNCHANGED) ---
class UNetGenerator3DWithSideInput(nn.Module):
    def __init__(self, in_channels=3, input_depth=4, side_input_processed_channels=16):
        super(UNetGenerator3DWithSideInput, self).__init__()
        self.fusion_block = nn.Sequential(
            nn.Conv3d(in_channels, 64, kernel_size=(input_depth, 4, 4), stride=(1, 2, 2), padding=(0, 1, 1), bias=False),
            nn.BatchNorm3d(64),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.side_input_processor = nn.Sequential(
            nn.Upsample(size=(64, 64), mode='bilinear', align_corners=False),
            nn.Conv2d(1, side_input_processed_channels // 2, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(side_input_processed_channels // 2, side_input_processed_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(side_input_processed_channels),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.enc1 = self.conv_block(64, 128, batch_norm=False)
        self.enc2 = self.conv_block(128 + side_input_processed_channels, 256)
        self.enc3 = self.conv_block(256, 512)
        self.enc4 = self.conv_block(512, 512)
        self.enc5 = self.conv_block(512, 512)
        self.enc6 = self.conv_block(512, 512)
        self.enc7 = self.conv_block(512, 512, batch_norm=False)
        self.dec6 = self.deconv_block(512, 512, dropout=True)
        self.dec5 = self.deconv_block(1024, 512, dropout=True)
        self.dec4 = self.deconv_block(1024, 512, dropout=True)
        self.dec3 = self.deconv_block(1024, 512)
        self.dec2 = self.deconv_block(1024, 256)
        self.dec1 = self.deconv_block(512, 128)
        self.dec0 = self.deconv_block(256, 64)
        self.final_conv = nn.Sequential(
            nn.ConvTranspose2d(128, in_channels, kernel_size=4, stride=2, padding=1),
            nn.Tanh()
        )
    def conv_block(self, i, o, batch_norm=True):
        l = [nn.Conv2d(i, o, 4, 2, 1, bias=False)]
        if batch_norm: l.append(nn.BatchNorm2d(o))
        l.append(nn.LeakyReLU(0.2, inplace=True))
        return nn.Sequential(*l)
    def deconv_block(self, i, o, dropout=False):
        l = [nn.ConvTranspose2d(i, o, 4, 2, 1, bias=False), nn.BatchNorm2d(o), nn.ReLU(True)]
        if dropout: l.append(nn.Dropout(0.5))
        return nn.Sequential(*l)
    def forward(self, x, side_input):
        x = x.permute(0, 2, 1, 3, 4)
        fused = self.fusion_block(x)
        e0 = fused.squeeze(2)
        e1 = self.enc1(e0)
        processed_side = self.side_input_processor(side_input)
        e1_with_side = torch.cat([e1, processed_side], dim=1)
        e2 = self.enc2(e1_with_side)
        e3 = self.enc3(e2); e4 = self.enc4(e3)
        e5 = self.enc5(e4); e6 = self.enc6(e5); e7 = self.enc7(e6)
        d6 = self.dec6(e7)
        d5 = self.dec5(torch.cat([d6, e6], 1))
        d4 = self.dec4(torch.cat([d5, e5], 1))
        d3 = self.dec3(torch.cat([d4, e4], 1))
        d2 = self.dec2(torch.cat([d3, e3], 1))
        d1 = self.dec1(torch.cat([d2, e2], 1))
        d0 = self.dec0(torch.cat([d1, e1], 1))
        return self.final_conv(torch.cat([d0, e0], 1))

class PatchGANDiscriminator(nn.Module):
    def __init__(self, in_channels=3):
        super(PatchGANDiscriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(in_channels * 2, 64, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, True),
            nn.Conv2d(64, 128, 4, 2, 1, bias=False), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, True),
            nn.Conv2d(128, 256, 4, 2, 1, bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, True),
            nn.Conv2d(256, 512, 4, 1, 1, bias=False), nn.BatchNorm2d(512), nn.LeakyReLU(0.2, True),
            nn.Conv2d(512, 1, 4, 1, 1), nn.Sigmoid()
        )
    def forward(self, condition, target):
        return self.model(torch.cat([condition, target], dim=1))


# --- REFINED AND OPTIMIZED TRAINING FUNCTION ---
def train_pix2pix(epochs=600, batch_size=4, lr=0.0002, beta1=0.5,
                  l1_lambda=100.0, ssim_lambda=10.0, distance_weight_lambda=1.0,
                  dataset_max_dist=10, device='cuda' if torch.cuda.is_available() else 'cpu'):

    # --- 1. SETUP DATASET AND DATALOADER ---
    # Define transforms (now with normalization for [-1, 1] range required by Tanh activation)
    image_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # Normalizes to [-1, 1]
    ])
    side_frame_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.GaussianBlur(kernel_size=5, sigma=1.0)
    ])

    root_path = "/home/ag/lfi/dataset/lofimages"
    if not os.path.exists(root_path):
        raise FileNotFoundError(f"The specified root_path does not exist: {root_path}")
    data_folders = sorted([os.path.join(root_path, d) for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))])

    # Pass transforms to the dataset. We use the same max_dist as we will for normalization.
    dataset = LightFieldDataset(
        data_folders,
        num_samples=14000,
        min_dist=1,
        max_dist=dataset_max_dist,
        transform=image_transform,
        side_frame_transform=side_frame_transform
    )
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)

    # --- 2. SETUP MODELS, LOSSES, AND OPTIMIZERS ---
    generator = UNetGenerator3DWithSideInput().to(device)
    discriminator = PatchGANDiscriminator().to(device)

    # For weighted loss, we need per-sample losses before averaging
    gan_loss = nn.BCELoss()
    l1_loss_fn = nn.L1Loss(reduction='none') # Get per-pixel loss
    # For pytorch-msssim, size_average=False gives per-sample loss
    ssim_module = SSIM(data_range=1.0, size_average=False, channel=3).to(device)

    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))
    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))

    # Calculate the max possible Manhattan distance for normalization
    # The 'x' shape with max_dist gives the largest possible value.
    max_possible_manhattan_dist = 8 * dataset_max_dist

    # --- 3. TRAINING LOOP ---
    print(f"Starting training on {device}...")
    for epoch in range(epochs):
        # Use tqdm for a nice progress bar
        loop = tqdm(dataloader, leave=True)
        for i, (input_stack, target_img, side_frame, manhattan_distances) in enumerate(loop):
            input_stack = input_stack.to(device)
            target_img = target_img.to(device)
            side_frame = side_frame.to(device)
            manhattan_distances = manhattan_distances.to(device)

            # Use the mean of input views as the condition for the discriminator
            conditional_input = torch.mean(input_stack, dim=1)

            # --- Train Discriminator ---
            optimizer_D.zero_grad()
            # Real
            real_pred = discriminator(conditional_input, target_img)
            loss_D_real = gan_loss(real_pred, torch.ones_like(real_pred, device=device))
            # Fake
            fake_img = generator(input_stack, side_frame)
            fake_pred = discriminator(conditional_input, fake_img.detach())
            loss_D_fake = gan_loss(fake_pred, torch.zeros_like(fake_pred, device=device))
            # Combined
            loss_D = (loss_D_real + loss_D_fake) * 0.5
            loss_D.backward()
            optimizer_D.step()

            # --- Train Generator ---
            optimizer_G.zero_grad()
            # Adversarial Loss
            fake_pred_for_G = discriminator(conditional_input, fake_img)
            loss_G_gan = gan_loss(fake_pred_for_G, torch.ones_like(fake_pred_for_G, device=device))

            # --- WEIGHTED RECONSTRUCTION LOSS ---
            # Create a weight for each sample in the batch based on its difficulty (Manhattan distance)
            # We normalize the distance and add 1, so weights are >= 1.
            # This ensures that even the easiest samples (dist=0) still have a weight of 1.
            distance_weights = 1.0 + distance_weight_lambda * (manhattan_distances / max_possible_manhattan_dist)

            # Reshape weights to be [batch_size, 1, 1, 1] for broadcasting with per-pixel loss
            distance_weights_reshaped = distance_weights.view(-1, 1, 1, 1)

            # L1 Loss
            per_pixel_l1 = l1_loss_fn(fake_img, target_img)
            weighted_l1_loss = (per_pixel_l1 * distance_weights_reshaped).mean() * l1_lambda

            # SSIM Loss (Images must be in [0, 1] range for SSIM)
            # We shift from [-1, 1] to [0, 1] by adding 1 and dividing by 2. Data range is now 1.0.
            fake_img_0_1 = (fake_img + 1) / 2
            target_img_0_1 = (target_img + 1) / 2
            per_sample_ssim = 1 - ssim_module(fake_img_0_1, target_img_0_1)
            weighted_ssim_loss = (per_sample_ssim * distance_weights).mean() * ssim_lambda

            # Combined Generator Loss
            loss_G = loss_G_gan + weighted_l1_loss + weighted_ssim_loss
            loss_G.backward()
            optimizer_G.step()

            # Update progress bar
            loop.set_description(f"Epoch [{epoch+1}/{epochs}]")
            loop.set_postfix(loss_D=loss_D.item(), loss_G=loss_G.item(),
                             L1=weighted_l1_loss.item(), SSIM=weighted_ssim_loss.item())

        if (epoch + 1) % 10 == 0:
            torch.save(generator.state_dict(), f'generator_dist_final_weighted_epoch_{epoch+1}.pth')
            torch.save(discriminator.state_dict(), f'discriminator_dist_final_weighted_epoch_{epoch+1}.pth')
            print(f"\nSaved models at epoch {epoch+1}")

    print("Training finished!")

if __name__ == '__main__':
    train_pix2pix(epochs=400, batch_size=4, device='cuda' if torch.cuda.is_available() else 'cpu')
